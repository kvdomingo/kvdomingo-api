<p>
    For this activity, I generated the basic shapes using the Python Imaging Library (PIL). This let me define the centroid and pseudo-radius (distance from the centroid to the midpoint of an edge) for each shape analytically, and therefore, I know precisely what their dimensions and areas will be. The shapes are shown in Fig. 1, all with size 1024 $\times$ 1024.
</p>

<div id="fig-shapes" class="container text-center my-5">
    <div class="row row-cols-1 row-cols-md-4"></div>
    <p>
        Figure 1: Basic binary shapes generated using the Python PIL library.
    </p>
</div>

<p>
    For extracting the edges of the shapes, I explored a few edge detection algorithms, eventually settling with the following:
    <ul>
        <li>
            <strong>PIL's <code>FIND_EDGES</code> filter</strong>: this built-in function works like a charm and can be easily implemented as a one-liner. The documentation doesn't describe what it does exactly, but after digging through the source code [<a href="#Wiredfool2016">1</a>], it found that it simply convolves an image with a spot kernel of the form
            <span id="eq-spot">
                \begin{equation}
                    G =
                    \begin{pmatrix}
                        -1 & -1 & -1 \\
                        -1 &  8 & -1 \\
                        -1 & -1 & -1
                    \end{pmatrix}
                \end{equation}
            </span>
        </li>
        <li>
            <strong>Sobel filter</strong>: approximates the gradient of an image's intensity function [<a href="#Sobel2014">2</a>]. Convolves images with two kernels (one for each direction)
            <span id="eq-sobel">
                \begin{align}
                    G_x & =
                    \begin{pmatrix}
                        -1 & 0 & 1 \\
                        -2 & 0 & 2 \\
                        -1 & 0 & 1
                    \end{pmatrix} \\
                    G_y & = G_x^\top
                \end{align}
            </span>
        </li>
        <li>
            <strong>Prewitt filter</strong>: also approximates the gradient of image intensity and acts in two directions, similar to the Sobel filter [<a href="#Prewitt1970">3</a>]. Its kernel is of the form
            <span id="eq-prewitt">
                \begin{align}
                    G_x & =
                    \begin{pmatrix}
                        1 & 0 & -1 \\
                        1 & 0 & -1 \\
                        1 & 0 & -1
                    \end{pmatrix} \\
                    G_y & = G_x^\top
                \end{align}
            </span>
        </li>
        <li>
            <strong>Laplacian filter</strong>: calculates the second-order derivatives of the image intensity in one pass [<a href="#Laplacian2018">4</a>]. Because of its sensitivity to noise, I first applied a 3 $\times$ 3 Gaussan filter with 0 standard deviation before applying the Laplacian filter. Its kernel is of the form
            <span id="eq-canny">
                \begin{equation}
                    G_x =
                    \begin{pmatrix}
                         0 & -1 &  0 \\
                        -1 &  4 & -1 \\
                         0 & -1 &  0
                    \end{pmatrix}
                \end{equation}
            </span>
        </li>
        <li>
            <strong>Canny filter</strong>: a multistage edge-detection algorithm which is highly versatile and efficient [<a href="#Canny1986">5</a>].
        </li>
    </ul>
</p>

<p>
    From the traced edges, the area it encloses can be calculated using a discretized form of Green's theorem [<a href="#Soriano2019">6</a>]
    <span id="eq-green">
        \begin{equation}
            A = \frac{1}{2} \sum_{i=1}^N \left( x_{i-1} y_i - y_{i-1} x_i \right)
        \end{equation}
    </span>
    where $x_i, y_i$ are the pixel coordinates, and $N$ is the number of pixels on the boundary. The results for each algorithm, along with their relative errors, are shown in Table <a href="#table-areas">1</a>, and the edge-traced images are shown in Figs. <a href="#fig-circles">2</a>-<a href="#fig-triangles">5</a>.
</p>

<div id="fig-circles" class="container text-center my-5">
    <div class="row row-cols-1 row-cols-md-5"></div>
    <p>
        Figure 2: Edges extracted from the circle using different algorithms.
    </p>
</div>

<div id="fig-squares" class="container text-center my-5">
    <div class="row row-cols-1 row-cols-md-5"></div>
    <p>
        Figure 3: Edges extracted from the square using different algorithms.
    </p>
</div>

<div id="fig-trapezoids" class="container text-center my-5">
    <div class="row row-cols-1 row-cols-md-5"></div>
    <p>
        Figure 4: Edges extracted from the trapezoid using different algorithms.
    </p>
</div>

<div id="fig-triangles" class="container text-center my-5">
    <div class="row row-cols-1 row-cols-md-5"></div>
    <p>
        Figure 5: Edges extracted from the triangle using different algorithms.
    </p>
</div>

<p>
    Notice how the Sobel &amp; Prewitt filters perform very similarly because they are both gradient-based methods. Due to their directional dependence, we can notice how the edges, particularly on the lower-right portions, are not being detected very well. Upon closer examination, however, the edges <i>are</i> being detected but are very faint (low magnitude). Spot and Canny, on the other hand, produce very clean and accurate edges. Laplacian also detects a clean edge but is somewhat low in magnitude.
</p>

<div class="container text-center my-5 px-md-5 w-responsive">
    <p id="table-areas">
        Table 1: Actual and calculated areas (px$^2$) of each shape and their corresponding relative errors. The percentages in bold indicate the best-performing algorithm for each shape.
    </p>
    <div class="table-responsive">
        <table class="table table-bordered table-striped">
            <thead>
                <tr>
                    <th scope="col">Shape</th>
                    <th scope="col">Actual</th>
                    <th scope="col">Spot</th>
                    <th scope="col">Sobel</th>
                    <th scope="col">Prewitt</th>
                    <th scope="col">Laplacian</th>
                    <th scope="col">Canny</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>circle</td>
                    <td>502,655</td>
                    <td>501,584</td>
                    <td>503,187</td>
                    <td>503,187</td>
                    <td>503,198</td>
                    <td>503,182</td>
                </tr>
                <tr>
                    <td></td>
                    <td></td>
                    <td>0.21%</td>
                    <td>0.11%</td>
                    <td>0.11%</td>
                    <td>0.11%</td>
                    <td><strong>0.10%</strong></td>
                </tr>
                <tr>
                    <td>square</td>
                    <td>640,000</td>
                    <td>639,800</td>
                    <td>641,404</td>
                    <td>641,404</td>
                    <td>641,416</td>
                    <td>641,398</td>
                </tr>
                <tr>
                    <td></td>
                    <td></td>
                    <td><strong>0.03%</strong></td>
                    <td>0.22%</td>
                    <td>0.22%</td>
                    <td>0.22%</td>
                    <td>0.22%</td>
                </tr>
                <tr>
                    <td>trapezoid</td>
                    <td>426,667</td>
                    <td>426,399</td>
                    <td>428,002</td>
                    <td>428,002</td>
                    <td>428,013</td>
                    <td>427,731</td>
                </tr>
                <tr>
                    <td></td>
                    <td></td>
                    <td><strong>0.06%</strong></td>
                    <td>0.31%</td>
                    <td>0.31%</td>
                    <td>0.32%</td>
                    <td>0.25%</td>
                </tr>
                <tr>
                    <td>triangle</td>
                    <td>320,000</td>
                    <td>319,102</td>
                    <td>320,705</td>
                    <td>320,705</td>
                    <td>320,714</td>
                    <td>320,304</td>
                </tr>
                <tr>
                    <td></td>
                    <td></td>
                    <td>0.28%</td>
                    <td>0.22%</td>
                    <td>0.22%</td>
                    <td>0.22%</td>
                    <td><strong>0.09%</strong></td>
                </tr>
            </tbody>
        </table>
    </div>
</div>

<p>
    I chose the CS Amphitheater as a location of interest for calculating the area on a map. I obtained its actual area using Google Earth's Ruler tool, then proceeded to import it into Photoshop. I then applied enough threshold so that the yellow line was clear and isolated from the other white spots. I manually erased any remaining white artifacts until only the circle and the line indicating the radius were left. I then measured the length of the radius in pixels, this time using Photoshop's Ruler tool. Since the actual radius in meters was also provided by Google Earth's Ruler tool, I was able to formulate the pixel-to-meter conversion as

    <span id="eq-calibration">
        \begin{equation}
            x_{\mathrm{m}} = x_{\mathrm{px}} \times \frac{37.62\textrm{ m}}{389\textrm{ px}}
        \end{equation}
    </span>

    Via Green's theorem, I was able to obtain the Amphitheater's area in pixels. However, this cannot be converted directly to real units using (<a href="#eq-calibration">6</a>) because our current units are area, while the conversion equation only works for units of length. Since the amphitheater appears fairly circular, I used the formula for the area of a circle $A = \pi r^2$ and solved for $r$. I can now plug in this $r$ directly into (<a href="#eq-calibration">6</a>) and finally, multiply it again by $\pi r$ to get the area in real units. The calculated areas for the different algorithms are shown in Table <a href="#tab-amphi">2</a>, and the edge-traced images are shown in Fig. <a href="#fig-amphi">6</a>.
</p>

<div class="container text-center my-5 w-responsive">
    <p id="table-areas" class="px-md-5">
        Table 1: Actual and calculated areas (px$^2$) of each shape and their corresponding relative errors. The percentages in bold indicate the best-performing algorithm for each shape.
    </p>
    <div class="table-responsive">
        <table class="table table-bordered table-striped">
            <thead>
                <tr>
                    <th scope="col">Actual</th>
                    <th scope="col">Spot</th>
                    <th scope="col">Sobel</th>
                    <th scope="col">Prewitt</th>
                    <th scope="col">Laplacian</th>
                    <th scope="col">Canny</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>4485.92</td>
                    <td>4600.44</td>
                    <td>4630.52</td>
                    <td>4630.55</td>
                    <td>4629.64</td>
                    <td>4634.90</td>
                </tr>
                <tr>
                    <td></td>
                    <td><strong>2.55%</strong></td>
                    <td>3.22%</td>
                    <td>3.22%</td>
                    <td>3.20%</td>
                    <td>3.32%</td>
                </tr>
            </tbody>
        </table>
    </div>
</div>

<div id="fig-amphi" class="container text-center my-5">
    <div class="row row-cols-1 row-cols-md-2">
        <div class="col">
            <img class="cld-responsive img-fluid mx-auto" data-src="https://res.cloudinary.com/kdphotography-assets/image/upload/c_scale,w_auto,dpr_auto/v1/svip/186/4-MeasuringArea/csamphi_map.png" />
            <p class="subfigure">Enclosed area in Google Earth</p>
        </div>
        <div class="col">
            <img class="cld-responsive img-fluid mx-auto" data-src="https://res.cloudinary.com/kdphotography-assets/image/upload/c_scale,w_auto,dpr_auto/v1/svip/186/4-MeasuringArea/csamphi.png" />
            <p class="subfigure">Applying threshold and isolating the ROI</p>
        </div>
        <div class="col">
            <img class="cld-responsive img-fluid mx-auto" data-src="https://res.cloudinary.com/kdphotography-assets/image/upload/c_scale,w_auto,dpr_auto/v1/svip/186/4-MeasuringArea/csamphi_spot.png" />
            <p class="subfigure">spot</p>
        </div>
        <div class="col">
            <img class="cld-responsive img-fluid mx-auto" data-src="https://res.cloudinary.com/kdphotography-assets/image/upload/c_scale,w_auto,dpr_auto/v1/svip/186/4-MeasuringArea/csamphi_sobel.png" />
            <p class="subfigure">Sobel/Prewitt</p>
        </div>
        <div class="col">
            <img class="cld-responsive img-fluid mx-auto" data-src="https://res.cloudinary.com/kdphotography-assets/image/upload/c_scale,w_auto,dpr_auto/v1/svip/186/4-MeasuringArea/csamphi_laplacian.png" />
            <p class="subfigure">Laplacian</p>
        </div>
        <div class="col">
            <img class="cld-responsive img-fluid mx-auto" data-src="https://res.cloudinary.com/kdphotography-assets/image/upload/c_scale,w_auto,dpr_auto/v1/svip/186/4-MeasuringArea/csamphi_canny.png" />
            <p class="subfigure">Canny</p>
        </div>
    </div>
    <p>
        Figure 6: Detecting the edges of the CS Amphitheater.
    </p>
</div>

<p>
    We can observe that in general, the spot filter works best in edge detection. Upon further investigation, I found out that the spot kernel is actually a variant of the Laplacian kernel and produces exceptional results on arbitrary images.
</p>


<h3>References</h3>
<ol class="reference">
    <li id="Wiredfool2016">
        wiredfool, A. Clark, Hugo, A. Murray, A. Karpinsky, C. Gohlke, B. Crowell, D. Schmidt, A. Houghton, and S. Johnson, <a href="https://github.com/python-pillow/Pillow/tree/5.4.x" target="_blank">Pillow: The friendly PIL fork</a> (2016).
    </li>
    <li id="Sobel2014">
        I. Sobel, An isotropic 3 $\times$ 3 image gradient operator, <i>Presentation at Stanford A.I. Project 1968</i> (2014).
    </li>
    <li id="Prewitt1970">
        J. M. S. Prewitt, Object enhancement and extraction, <i>Picture processing and psychopictorics</i> (1970).
    </li>
    <li id="Laplacian2018">
        N. Tsankashvili, <a href="https://medium.com/@nikatsanka/comparing-edge-detection-methods-638a2919476e" target="_blank">Comparing edge detection methods</a> (2018).
    </li>
    <li id="Canny1986">
        J. F. Canny, A computational approach to edge detection, <i>IEEE transactions on pattern analysis and machine intelligence</i> <strong>8</strong>, 679 (1986).
    </li>
    <li id="Soriano2019">
        M. N. Soriano, <i>Measuring area from images</i> (2019).
    </li>
</ol>
